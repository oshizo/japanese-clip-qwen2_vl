{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import resize_image\n",
    "\n",
    "\n",
    "def transform_item(item):\n",
    "    return {\n",
    "        \"text\": item[\"annotations\"][\"caption\"][0],\n",
    "        \"pos_image\": resize_image(item[\"image\"], 224),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import DatasetDict\n",
    "\n",
    "N = 1000\n",
    "ds = datasets.load_dataset(\"shunk031/STAIR-Captions\", \"v1.2.0\", split=\"train\")\n",
    "ds = ds.select(range(N)).map(\n",
    "    transform_item, num_proc=12, remove_columns=ds.column_names\n",
    ")\n",
    "\n",
    "train_dd = DatasetDict(\n",
    "    {\n",
    "        \"stair captions\": ds,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_clip_qwen2vl import CLIPQwen2VLWrapper\n",
    "\n",
    "# model_pathには initialize_model で出力したパスを指定する\n",
    "clip = CLIPQwen2VLWrapper(\"./clip\", enable_text_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=128,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    use_rslora=True,\n",
    "    target_modules=[\"attn.qkv\", \"attn.proj\", \"fc1\", \"fc2\", \"mlp.0\", \"mlp.2\"],\n",
    "    modules_to_save=[\"vision_projection\"],\n",
    ")\n",
    "clip.model = get_peft_model(clip.model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(modules=[clip], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import PngImagePlugin\n",
    "\n",
    "# 学習中のエラー防止\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import ImageTextCachedMultipleNegativesRankingLoss\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerTrainer,\n",
    ")\n",
    "\n",
    "loss = ImageTextCachedMultipleNegativesRankingLoss(model=model, mini_batch_size=1)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    report_to=\"none\",\n",
    "    output_dir=\"./outputs\",\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    eval_strategy=\"no\",\n",
    "    bf16=True,\n",
    "    per_device_train_batch_size=64,\n",
    "    run_name=\"v0.1\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dd,\n",
    "    loss=loss,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
